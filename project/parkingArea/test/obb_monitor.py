"""
YOLO-OBB ì‹¤í–‰ ê²°ê³¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
OBB (Oriented Bounding Box) ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆëŠ” í…ŒìŠ¤íŠ¸ ë„êµ¬
"""

import os
import sys
from typing import Dict, List, Optional, Tuple

import cv2
import matplotlib.patches as patches
import matplotlib.pyplot as plt
import numpy as np
import torch
from matplotlib.patches import Polygon
from sklearn.cluster import DBSCAN
from ultralytics import YOLO

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class OBBMonitor:
    """YOLO-OBB ê²°ê³¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""

    def __init__(self, model_path: str = "../../yolov8n-obb.pt"):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")

        # YOLO-OBB ëª¨ë¸ ë¡œë“œ
        try:
            self.model = YOLO(model_path)
            print(f"âœ… YOLO-OBB ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None

        # COCO í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘
        self.class_names = {
            0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',
            5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',
            10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',
            14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow'
        }

        # ì°¨ëŸ‰ ê´€ë ¨ í´ë˜ìŠ¤
        self.vehicle_classes = [2, 3, 5, 7]  # car, motorcycle, bus, truck

        # ìƒ‰ìƒ ë§¤í•‘
        self.colors = {
            2: (0, 255, 0),    # car - ë…¹ìƒ‰
            3: (255, 0, 0),    # motorcycle - íŒŒë€ìƒ‰
            5: (0, 0, 255),    # bus - ë¹¨ê°„ìƒ‰
            7: (255, 255, 0),  # truck - ì²­ë¡ìƒ‰
        }

        # Perspective Transform ê´€ë ¨ ë³€ìˆ˜ë“¤
        self.perspective_matrix = None
        self.detected_lines = []

    def detect_with_obb(self, image_path: str, conf_threshold: float = 0.25):
        """YOLO-OBBë¡œ ê°ì²´ ê°ì§€"""
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None, None

        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return None, None

        print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")

        # YOLO-OBB ì¶”ë¡ 
        try:
            results = self.model(image, verbose=False, conf=conf_threshold)
            print(f"ğŸ” ì¶”ë¡  ì™„ë£Œ (ì‹ ë¢°ë„ ì„ê³„ê°’: {conf_threshold})")
            return image, results
        except Exception as e:
            print(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return image, None

    def extract_detections(self, results):
        """ê°ì§€ ê²°ê³¼ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        detections = []

        for result in results:
            # OBB ê²°ê³¼ ì²˜ë¦¬
            if hasattr(result, 'obb') and result.obb is not None:
                print(f"ğŸ“¦ OBB ê°ì§€: {len(result.obb)} ê°œ ê°ì²´")

                for i, (obb, conf, cls) in enumerate(zip(result.obb.xyxyxyxy, result.obb.conf, result.obb.cls)):
                    class_id = int(cls)
                    confidence = float(conf)
                    class_name = self.class_names.get(class_id, f"class_{class_id}")

                    # OBB ì ë“¤ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
                    obb_points = obb.cpu().numpy().reshape(-1, 2)

                    # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                    x_coords = obb_points[:, 0]
                    y_coords = obb_points[:, 1]
                    bbox = [int(np.min(x_coords)), int(np.min(y_coords)),
                           int(np.max(x_coords)), int(np.max(y_coords))]

                    # í¬ê¸° ê³„ì‚°
                    width = np.linalg.norm(obb_points[1] - obb_points[0])
                    height = np.linalg.norm(obb_points[2] - obb_points[1])
                    area = width * height

                    # ì¤‘ì‹¬ì 
                    center = [int(np.mean(x_coords)), int(np.mean(y_coords))]

                    # íšŒì „ ê°ë„ ê³„ì‚°
                    angle = np.arctan2(obb_points[1][1] - obb_points[0][1],
                                     obb_points[1][0] - obb_points[0][0]) * 180 / np.pi

                    detection = {
                        'id': i,
                        'class_id': class_id,
                        'class_name': class_name,
                        'confidence': confidence,
                        'obb_points': obb_points,
                        'bbox': bbox,
                        'center': center,
                        'size': (width, height),
                        'area': area,
                        'angle': angle,
                        'is_vehicle': class_id in self.vehicle_classes
                    }
                    detections.append(detection)

            # ì¼ë°˜ ë°•ìŠ¤ ê²°ê³¼ë„ ì²˜ë¦¬ (OBBê°€ ì—†ëŠ” ê²½ìš°)
            elif hasattr(result, 'boxes') and result.boxes is not None:
                print(f"ğŸ“¦ ì¼ë°˜ ë°•ìŠ¤ ê°ì§€: {len(result.boxes)} ê°œ ê°ì²´")

                for i, (box, conf, cls) in enumerate(zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls)):
                    class_id = int(cls)
                    confidence = float(conf)
                    class_name = self.class_names.get(class_id, f"class_{class_id}")

                    # ë°•ìŠ¤ ì¢Œí‘œ
                    x1, y1, x2, y2 = [int(x) for x in box.cpu().numpy()]
                    bbox = [x1, y1, x2, y2]

                    # ì‚¬ê°í˜• ëª¨ì„œë¦¬ ì ë“¤ (OBB í˜•íƒœë¡œ ë³€í™˜)
                    obb_points = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32)

                    # í¬ê¸° ê³„ì‚°
                    width = x2 - x1
                    height = y2 - y1
                    area = width * height

                    # ì¤‘ì‹¬ì 
                    center = [int((x1 + x2) / 2), int((y1 + y2) / 2)]

                    detection = {
                        'id': i,
                        'class_id': class_id,
                        'class_name': class_name,
                        'confidence': confidence,
                        'obb_points': obb_points,
                        'bbox': bbox,
                        'center': center,
                        'size': (width, height),
                        'area': area,
                        'angle': 0.0,  # ì¼ë°˜ ë°•ìŠ¤ëŠ” íšŒì „ ì—†ìŒ
                        'is_vehicle': class_id in self.vehicle_classes
                    }
                    detections.append(detection)

        return detections

    def detect_lines_from_obb(self, detections: List[Dict]) -> List[Tuple[float, float]]:
        """OBB polygonê³¼ ê²¹ì¹˜ëŠ” ìˆ˜ì§/ìˆ˜í‰ ì„ ë¶„ë“¤ ìƒì„±"""
        lines = []

        # ì°¨ëŸ‰ë§Œ í•„í„°ë§
        vehicles = [d for d in detections if d['is_vehicle']]

        if len(vehicles) < 1:
            print("âš ï¸ ì§ì„  ê²€ì¶œì„ ìœ„í•œ ì°¨ëŸ‰ì´ ì—†ìŠµë‹ˆë‹¤")
            return lines

        print(f"ğŸš— {len(vehicles)}ëŒ€ ì°¨ëŸ‰ì—ì„œ ìˆ˜ì§/ìˆ˜í‰ ì„ ë¶„ ìƒì„±")

        # ê° ì°¨ëŸ‰ì— ëŒ€í•´ ìˆ˜ì§/ìˆ˜í‰ ì„ ë¶„ë“¤ ìƒì„±
        for vehicle_idx, vehicle in enumerate(vehicles):
            obb_points = vehicle['obb_points']
            if len(obb_points) >= 4:
                points = np.array(obb_points)

                # ì°¨ëŸ‰ ê²½ê³„ ìƒì ê³„ì‚°
                min_x = np.min(points[:, 0])
                max_x = np.max(points[:, 0])
                min_y = np.min(points[:, 1])
                max_y = np.max(points[:, 1])

                center_x, center_y = vehicle['center']

                # í™•ì¥ í”½ì…€ (polygon ì£¼ë³€ìœ¼ë¡œ ì„ ë¶„ í™•ì¥)
                extend_pixels = 30

                # 1. ìˆ˜ì§ ì„ ë¶„ë“¤ ìƒì„± (ì°¨ëŸ‰ ì¢Œìš°)
                # ì¢Œì¸¡ ìˆ˜ì§ì„ 
                left_x = min_x - extend_pixels
                vertical_slope_left = float('inf')  # ìˆ˜ì§ì„  í‘œí˜„ì„ ìœ„í•œ íŠ¹ìˆ˜ê°’
                lines.append(('vertical', left_x, min_y - extend_pixels, max_y + extend_pixels))

                # ìš°ì¸¡ ìˆ˜ì§ì„ 
                right_x = max_x + extend_pixels
                lines.append(('vertical', right_x, min_y - extend_pixels, max_y + extend_pixels))

                # ì¤‘ì•™ ìˆ˜ì§ì„  (ì°¨ëŸ‰ ì¤‘ì‹¬)
                lines.append(('vertical', center_x, min_y - extend_pixels, max_y + extend_pixels))

                # 2. ìˆ˜í‰ ì„ ë¶„ë“¤ ìƒì„± (ì°¨ëŸ‰ ìƒí•˜)
                # ìƒë‹¨ ìˆ˜í‰ì„ 
                top_y = min_y - extend_pixels
                lines.append(('horizontal', top_y, min_x - extend_pixels, max_x + extend_pixels))

                # í•˜ë‹¨ ìˆ˜í‰ì„ 
                bottom_y = max_y + extend_pixels
                lines.append(('horizontal', bottom_y, min_x - extend_pixels, max_x + extend_pixels))

                # ì¤‘ì•™ ìˆ˜í‰ì„  (ì°¨ëŸ‰ ì¤‘ì‹¬)
                lines.append(('horizontal', center_y, min_x - extend_pixels, max_x + extend_pixels))

                print(f"   ì°¨ëŸ‰ {vehicle_idx+1}: ìˆ˜ì§ì„  3ê°œ, ìˆ˜í‰ì„  3ê°œ ìƒì„±")

        print(f"ğŸ” ì´ ìƒì„±ëœ ì„ ë¶„: {len(lines)}ê°œ")

        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì‹œê°í™”ë¥¼ ìœ„í•´)
        converted_lines = []
        for line_data in lines:
            if line_data[0] == 'vertical':
                # ìˆ˜ì§ì„ : x=ìƒìˆ˜ í˜•íƒœë¥¼ ê¸°ìš¸ê¸°ê°€ ë§¤ìš° í° ì§ì„ ìœ¼ë¡œ ë³€í™˜
                x = line_data[1]
                y1, y2 = line_data[2], line_data[3]
                slope = 1000  # ë§¤ìš° í° ê¸°ìš¸ê¸°ë¡œ ìˆ˜ì§ì„  ê·¼ì‚¬
                intercept = y1 - slope * x
                converted_lines.append((slope, intercept))
            else:  # horizontal
                # ìˆ˜í‰ì„ : y=ìƒìˆ˜ í˜•íƒœ
                y = line_data[1]
                x1, x2 = line_data[2], line_data[3]
                slope = 0  # ìˆ˜í‰ì„ 
                intercept = y
                converted_lines.append((slope, intercept))

        self.detected_lines = converted_lines
        self.line_segments = lines  # ì›ë³¸ ì„ ë¶„ ì •ë³´ ì €ì¥
        return converted_lines

    def apply_perspective_transform(self, image, lines: List[Tuple[float, float]]) -> Optional[np.ndarray]:
        """ê²€ì¶œëœ ìˆ˜ì§/ìˆ˜í‰ ì„ ë¶„ë“¤ì„ ì´ìš©í•œ perspective transform ì ìš©"""
        if not hasattr(self, 'line_segments') or not self.line_segments:
            print("âš ï¸ ì„ ë¶„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        h, w = image.shape[:2]

        # ìˆ˜ì§ì„ ê³¼ ìˆ˜í‰ì„  ë¶„ë¦¬
        vertical_lines = []
        horizontal_lines = []

        for line_data in self.line_segments:
            if line_data[0] == 'vertical':
                vertical_lines.append(line_data)
            elif line_data[0] == 'horizontal':
                horizontal_lines.append(line_data)

        print(f"ï¿½ Transformìš© ì„ ë¶„: ìˆ˜ì§ {len(vertical_lines)}ê°œ, ìˆ˜í‰ {len(horizontal_lines)}ê°œ")

        if len(vertical_lines) >= 2 and len(horizontal_lines) >= 2:
            # ìˆ˜ì§ì„  2ê°œì™€ ìˆ˜í‰ì„  2ê°œë¥¼ ì„ íƒí•˜ì—¬ ì§ì‚¬ê°í˜• ê²©ì ìƒì„±
            print("ğŸ”² ì§ì‚¬ê°í˜• ê²©ì ê¸°ë°˜ ë³€í™˜")

            # ê°€ì¥ ë°”ê¹¥ìª½ ìˆ˜ì§ì„ ë“¤ ì„ íƒ
            v_lines_sorted = sorted(vertical_lines, key=lambda x: x[1])  # x ì¢Œí‘œë¡œ ì •ë ¬
            left_vertical = v_lines_sorted[0]
            right_vertical = v_lines_sorted[-1]

            # ê°€ì¥ ë°”ê¹¥ìª½ ìˆ˜í‰ì„ ë“¤ ì„ íƒ
            h_lines_sorted = sorted(horizontal_lines, key=lambda x: x[1])  # y ì¢Œí‘œë¡œ ì •ë ¬
            top_horizontal = h_lines_sorted[0]
            bottom_horizontal = h_lines_sorted[-1]

            # êµì ë“¤ ê³„ì‚°
            left_x = left_vertical[1]
            right_x = right_vertical[1]
            top_y = top_horizontal[1]
            bottom_y = bottom_horizontal[1]

            # ì›ë³¸ í¬ì¸íŠ¸ (í˜„ì¬ ê¸°ìš¸ì–´ì§„ ê²©ìì˜ êµì ë“¤)
            src_points = np.array([
                [left_x, top_y],      # ì¢Œìƒ
                [right_x, top_y],     # ìš°ìƒ
                [left_x, bottom_y],   # ì¢Œí•˜
                [right_x, bottom_y]   # ìš°í•˜
            ], dtype=np.float32)

            # ëª©í‘œ í¬ì¸íŠ¸ (ì™„ì „í•œ ì§ì‚¬ê°í˜•)
            margin = 50
            dst_points = np.array([
                [margin, margin],                    # ì¢Œìƒ
                [w - margin, margin],                # ìš°ìƒ
                [margin, h - margin],                # ì¢Œí•˜
                [w - margin, h - margin]             # ìš°í•˜
            ], dtype=np.float32)

        elif len(vertical_lines) >= 2:
            # ìˆ˜ì§ì„ ë§Œìœ¼ë¡œ ë³€í™˜
            print("ğŸ“ ìˆ˜ì§ì„  ê¸°ë°˜ ë³€í™˜")

            v_lines_sorted = sorted(vertical_lines, key=lambda x: x[1])
            left_vertical = v_lines_sorted[0]
            right_vertical = v_lines_sorted[-1]

            left_x = left_vertical[1]
            right_x = right_vertical[1]

            # ì¤‘ì•™ y ì¢Œí‘œë“¤
            top_y = h * 0.2
            bottom_y = h * 0.8

            src_points = np.array([
                [left_x, top_y],
                [right_x, top_y],
                [left_x, bottom_y],
                [right_x, bottom_y]
            ], dtype=np.float32)

            # ìˆ˜ì§ìœ¼ë¡œ ë§Œë“¤ê¸°
            center_x = w * 0.5
            width_half = abs(right_x - left_x) * 0.5

            dst_points = np.array([
                [center_x - width_half, top_y],
                [center_x + width_half, top_y],
                [center_x - width_half, bottom_y],
                [center_x + width_half, bottom_y]
            ], dtype=np.float32)

        elif len(horizontal_lines) >= 2:
            # ìˆ˜í‰ì„ ë§Œìœ¼ë¡œ ë³€í™˜
            print("ğŸ“ ìˆ˜í‰ì„  ê¸°ë°˜ ë³€í™˜")

            h_lines_sorted = sorted(horizontal_lines, key=lambda x: x[1])
            top_horizontal = h_lines_sorted[0]
            bottom_horizontal = h_lines_sorted[-1]

            top_y = top_horizontal[1]
            bottom_y = bottom_horizontal[1]

            # ì¤‘ì•™ x ì¢Œí‘œë“¤
            left_x = w * 0.2
            right_x = w * 0.8

            src_points = np.array([
                [left_x, top_y],
                [right_x, top_y],
                [left_x, bottom_y],
                [right_x, bottom_y]
            ], dtype=np.float32)

            # ìˆ˜í‰ìœ¼ë¡œ ë§Œë“¤ê¸°
            center_y = h * 0.5
            height_half = abs(bottom_y - top_y) * 0.5

            dst_points = np.array([
                [left_x, center_y - height_half],
                [right_x, center_y - height_half],
                [left_x, center_y + height_half],
                [right_x, center_y + height_half]
            ], dtype=np.float32)
        else:
            print("âš ï¸ Transformì„ ìœ„í•œ ì¶©ë¶„í•œ ì„ ë¶„ì´ ì—†ìŠµë‹ˆë‹¤")
            return None

        try:
            # Perspective ë³€í™˜ í–‰ë ¬ ê³„ì‚°
            self.perspective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)

            # ë³€í™˜ ì ìš©
            transformed = cv2.warpPerspective(image, self.perspective_matrix, (w, h))

            print("âœ… ìˆ˜ì§/ìˆ˜í‰ ì„ ë¶„ ê¸°ë°˜ ë³€í™˜ ì™„ë£Œ")
            return transformed

        except Exception as e:
            print(f"âš ï¸ Transform ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None

    def visualize_detections(self, image, detections, save_path: Optional[str] = None,
                           transformed_image: Optional[np.ndarray] = None,
                           lines: Optional[List[Tuple[float, float]]] = None):
        """ê°ì§€ ê²°ê³¼ ì‹œê°í™”"""
        # OpenCV ì´ë¯¸ì§€ë¥¼ matplotlibìš©ìœ¼ë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # ì°¨ëŸ‰ë§Œ í•„í„°ë§
        vehicles = [d for d in detections if d['is_vehicle']]
        all_objects = detections

        # Figure ì„¤ì • - 2x3 ë ˆì´ì•„ì›ƒìœ¼ë¡œ í™•ì¥
        fig, axes = plt.subplots(2, 3, figsize=(24, 16))
        fig.suptitle('YOLO-OBB ê°ì§€ ê²°ê³¼ ë° Perspective Transform ëª¨ë‹ˆí„°ë§', fontsize=16, fontweight='bold')

        # 1. ì›ë³¸ ì´ë¯¸ì§€
        axes[0, 0].imshow(image_rgb)
        axes[0, 0].set_title(f'ì›ë³¸ ì´ë¯¸ì§€ ({image.shape[1]}x{image.shape[0]})')
        axes[0, 0].axis('off')

        # 2. ëª¨ë“  ê°ì²´ ê°ì§€ ê²°ê³¼
        axes[0, 1].imshow(image_rgb)
        axes[0, 1].set_title(f'ëª¨ë“  ê°ì²´ ê°ì§€ ({len(all_objects)}ê°œ)')

        for detection in all_objects:
            # OBB ë‹¤ê°í˜• ê·¸ë¦¬ê¸°
            polygon = Polygon(detection['obb_points'],
                            fill=False,
                            edgecolor='red' if detection['is_vehicle'] else 'blue',
                            linewidth=2)
            axes[0, 1].add_patch(polygon)

            # # ë¼ë²¨ ì¶”ê°€
            # x, y = detection['center']
            # label = f"{detection['class_name']}\n{detection['confidence']:.2f}"
            # axes[0, 1].text(x, y, label,
            #                bbox=dict(boxstyle="round,pad=0.3", facecolor='yellow', alpha=0.7),
            #                fontsize=8, ha='center')

        axes[0, 1].axis('off')

        # 3. ì°¨ëŸ‰ë§Œ ìƒì„¸ í‘œì‹œ
        axes[1, 0].imshow(image_rgb)
        axes[1, 0].set_title(f'ì°¨ëŸ‰ ê°ì§€ ìƒì„¸ ({len(vehicles)}ëŒ€)')

        for i, vehicle in enumerate(vehicles):
            # OBB ë‹¤ê°í˜• ê·¸ë¦¬ê¸°
            color = self.colors.get(vehicle['class_id'], (128, 128, 128))
            color_normalized = tuple(c/255.0 for c in color)  # matplotlibìš© ìƒ‰ìƒ ì •ê·œí™”

            polygon = Polygon(vehicle['obb_points'],
                            fill=False,
                            edgecolor=color_normalized,
                            linewidth=3)
            axes[1, 0].add_patch(polygon)

            # ìƒì„¸ ì •ë³´ í‘œì‹œ
            x, y = vehicle['center']
            w, h = vehicle['size']
            info = f"V{i+1}: {vehicle['class_name']}\n"
            info += f"í¬ê¸°: {w:.0f}x{h:.0f}\n"
            info += f"ê°ë„: {vehicle['angle']:.1f}Â°\n"
            info += f"ì‹ ë¢°ë„: {vehicle['confidence']:.2f}"

            axes[1, 0].text(x, y, info,
                           bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8),
                           fontsize=7, ha='center', va='center')

            # ì¤‘ì‹¬ì  í‘œì‹œ
            axes[1, 0].plot(x, y, 'ro', markersize=5)

            # ID í‘œì‹œ
            axes[1, 0].text(x, y-30, f"ID: {i+1}",
                           bbox=dict(boxstyle="round,pad=0.2", facecolor=color_normalized, alpha=0.7),
                           fontsize=8, ha='center', fontweight='bold')

        axes[1, 0].axis('off')

        # 4. í†µê³„ ì°¨íŠ¸
        if vehicles:
            # ì°¨ëŸ‰ í¬ê¸° ë¶„í¬
            widths = [v['size'][0] for v in vehicles]
            heights = [v['size'][1] for v in vehicles]
            areas = [v['area'] for v in vehicles]

            axes[1, 1].scatter(widths, heights, c=areas, cmap='viridis', s=100, alpha=0.7)
            axes[1, 1].set_xlabel('í­ (í”½ì…€)')
            axes[1, 1].set_ylabel('ë†’ì´ (í”½ì…€)')
            axes[1, 1].set_title('ì°¨ëŸ‰ í¬ê¸° ë¶„í¬')
            axes[1, 1].grid(True, alpha=0.3)

            # ì°¨ëŸ‰ë³„ ë¼ë²¨
            for i, vehicle in enumerate(vehicles):
                w, h = vehicle['size']
                axes[1, 1].annotate(f'V{i+1}', (w, h),
                                  xytext=(5, 5), textcoords='offset points',
                                  fontsize=8, fontweight='bold')

            # ìƒ‰ìƒë°” ì¶”ê°€
            cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])
            cbar.set_label('ë©´ì  (í”½ì…€Â²)')
        else:
            axes[1, 1].text(0.5, 0.5, 'ê°ì§€ëœ ì°¨ëŸ‰ ì—†ìŒ',
                           ha='center', va='center', transform=axes[1, 1].transAxes,
                           fontsize=14, fontweight='bold')
            axes[1, 1].set_title('ì°¨ëŸ‰ í¬ê¸° ë¶„í¬')

        # 5. ê²€ì¶œëœ ì§ì„  í‘œì‹œ
        axes[0, 2].imshow(image_rgb)
        axes[0, 2].set_title(f'ê²€ì¶œëœ ì„ ë¶„ ({len(lines) if lines else 0}ê°œ)')

        # ì›ë³¸ ì„ ë¶„ ì •ë³´ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ë³€í™˜ëœ lines ì‚¬ìš©
        if hasattr(self, 'line_segments') and self.line_segments:
            # ìƒˆë¡œìš´ ì„ ë¶„ í˜•ì‹ìœ¼ë¡œ ê·¸ë¦¬ê¸°
            h, w = image.shape[:2]

            vertical_count = 0
            horizontal_count = 0

            for i, line_data in enumerate(self.line_segments):
                if line_data[0] == 'vertical':
                    # ìˆ˜ì§ì„ : x = ìƒìˆ˜
                    x = line_data[1]
                    y1, y2 = line_data[2], line_data[3]

                    # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ í´ë¦¬í•‘
                    y1 = max(0, min(h-1, y1))
                    y2 = max(0, min(h-1, y2))

                    color = 'red' if vertical_count % 2 == 0 else 'darkred'
                    axes[0, 2].plot([x, x], [y1, y2], color=color, linewidth=2,
                                   label=f'ìˆ˜ì§ì„  {vertical_count+1}')

                    # ë¼ë²¨ í‘œì‹œ
                    mid_y = (y1 + y2) / 2
                    axes[0, 2].text(x + 5, mid_y, f'V{vertical_count+1}',
                                   bbox=dict(boxstyle="round,pad=0.2", facecolor=color, alpha=0.7),
                                   fontsize=8, fontweight='bold', color='white')
                    vertical_count += 1

                elif line_data[0] == 'horizontal':
                    # ìˆ˜í‰ì„ : y = ìƒìˆ˜
                    y = line_data[1]
                    x1, x2 = line_data[2], line_data[3]

                    # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ í´ë¦¬í•‘
                    x1 = max(0, min(w-1, x1))
                    x2 = max(0, min(w-1, x2))

                    color = 'blue' if horizontal_count % 2 == 0 else 'darkblue'
                    axes[0, 2].plot([x1, x2], [y, y], color=color, linewidth=2,
                                   label=f'ìˆ˜í‰ì„  {horizontal_count+1}')

                    # ë¼ë²¨ í‘œì‹œ
                    mid_x = (x1 + x2) / 2
                    axes[0, 2].text(mid_x, y - 10, f'H{horizontal_count+1}',
                                   bbox=dict(boxstyle="round,pad=0.2", facecolor=color, alpha=0.7),
                                   fontsize=8, fontweight='bold', color='white')
                    horizontal_count += 1

            # ë²”ë¡€ë¥¼ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
            if vertical_count > 0 or horizontal_count > 0:
                legend_text = f"ìˆ˜ì§: {vertical_count}ê°œ, ìˆ˜í‰: {horizontal_count}ê°œ"
                axes[0, 2].text(0.02, 0.98, legend_text,
                               transform=axes[0, 2].transAxes,
                               bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8),
                               fontsize=10, fontweight='bold', va='top')

        elif lines:
            # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í‘œì‹œ (í˜¸í™˜ì„±ì„ ìœ„í•´)
            h, w = image.shape[:2]
            for i, (slope, intercept) in enumerate(lines):
                # ì§ì„ ì„ ì´ë¯¸ì§€ ê²½ê³„ê¹Œì§€ ê·¸ë¦¬ê¸°
                if abs(slope) > 100:  # ìˆ˜ì§ì„ ì— ê°€ê¹Œìš´ ê²½ìš°
                    x = int(-intercept / slope) if slope != 0 else w//2
                    axes[0, 2].plot([x, x], [0, h-1], color='red', linewidth=2,
                                   label=f'ìˆ˜ì§ì„  {i+1}')
                else:  # ì¼ë°˜ ì§ì„ 
                    x1, x2 = 0, w
                    y1 = int(slope * x1 + intercept)
                    y2 = int(slope * x2 + intercept)

                    # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ì—ì„œ í´ë¦¬í•‘
                    if y1 < 0:
                        y1 = 0
                        x1 = int((y1 - intercept) / slope) if abs(slope) > 1e-6 else 0
                    elif y1 >= h:
                        y1 = h - 1
                        x1 = int((y1 - intercept) / slope) if abs(slope) > 1e-6 else 0

                    if y2 < 0:
                        y2 = 0
                        x2 = int((y2 - intercept) / slope) if abs(slope) > 1e-6 else w
                    elif y2 >= h:
                        y2 = h - 1
                        x2 = int((y2 - intercept) / slope) if abs(slope) > 1e-6 else w

                    color = 'blue' if abs(slope) < 0.1 else 'green'
                    axes[0, 2].plot([x1, x2], [y1, y2], color=color, linewidth=2,
                                   label=f'Line {i+1}')
        else:
            axes[0, 2].text(0.5, 0.5, 'ê²€ì¶œëœ ì§ì„  ì—†ìŒ',
                           ha='center', va='center', transform=axes[0, 2].transAxes,
                           fontsize=14, fontweight='bold')

        axes[0, 2].axis('off')        # 6. Perspective Transform ê²°ê³¼
        if transformed_image is not None:
            transformed_rgb = cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB)
            axes[1, 2].imshow(transformed_rgb)
            axes[1, 2].set_title('Perspective Transform ê²°ê³¼')

            # ë³€í™˜ëœ ì´ë¯¸ì§€ì— ê²©ì ì˜¤ë²„ë ˆì´
            h, w = transformed_image.shape[:2]
            grid_size = 50

            # ìˆ˜ì§ì„  ê·¸ë¦¬ê¸°
            for x in range(0, w, grid_size):
                axes[1, 2].axvline(x=x, color='cyan', alpha=0.3, linewidth=1)

            # ìˆ˜í‰ì„  ê·¸ë¦¬ê¸°
            for y in range(0, h, grid_size):
                axes[1, 2].axhline(y=y, color='cyan', alpha=0.3, linewidth=1)

        else:
            axes[1, 2].text(0.5, 0.5, 'Transform ì‹¤íŒ¨\n(ì§ì„  ë¶€ì¡±)',
                           ha='center', va='center', transform=axes[1, 2].transAxes,
                           fontsize=14, fontweight='bold', color='red')
            axes[1, 2].set_title('Perspective Transform ê²°ê³¼')

        axes[1, 2].axis('off')

        plt.tight_layout()

        # ì €ì¥
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")

        # í™”ë©´ì— í‘œì‹œ
        plt.show()

        return fig

    def print_detection_summary(self, detections):
        """ê°ì§€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        vehicles = [d for d in detections if d['is_vehicle']]

        print("\n" + "="*60)
        print("ğŸ“Š YOLO-OBB ê°ì§€ ê²°ê³¼ ìš”ì•½")
        print("="*60)

        print(f"ğŸ” ì´ ê°ì§€ ê°ì²´: {len(detections)}ê°œ")
        print(f"ğŸš— ì°¨ëŸ‰: {len(vehicles)}ëŒ€")

        if vehicles:
            print("\nğŸ“‹ ì°¨ëŸ‰ ìƒì„¸ ì •ë³´:")
            print("ID | í´ë˜ìŠ¤     | ì‹ ë¢°ë„ | í¬ê¸°(WÃ—H)    | ë©´ì      | ê°ë„   | ì¤‘ì‹¬ì ")
            print("-" * 70)

            for i, vehicle in enumerate(vehicles):
                w, h = vehicle['size']
                x, y = vehicle['center']
                print(f"{i+1:2d} | {vehicle['class_name']:10s} | {vehicle['confidence']:6.2f} | "
                      f"{w:5.0f}Ã—{h:5.0f} | {vehicle['area']:8.0f} | {vehicle['angle']:6.1f}Â° | "
                      f"({x:3d},{y:3d})")

            # í¬ê¸° í†µê³„
            widths = [v['size'][0] for v in vehicles]
            heights = [v['size'][1] for v in vehicles]
            areas = [v['area'] for v in vehicles]

            print(f"\nğŸ“ í¬ê¸° í†µê³„:")
            print(f"  í­: í‰ê·  {np.mean(widths):.1f}px, í‘œì¤€í¸ì°¨ {np.std(widths):.1f}px")
            print(f"  ë†’ì´: í‰ê·  {np.mean(heights):.1f}px, í‘œì¤€í¸ì°¨ {np.std(heights):.1f}px")
            print(f"  ë©´ì : í‰ê·  {np.mean(areas):.0f}pxÂ², í‘œì¤€í¸ì°¨ {np.std(areas):.0f}pxÂ²")

            # í¬ê¸° ê· ì¼ì„± ê³„ì‚°
            size_uniformity = 100 - (np.std(widths) + np.std(heights)) / (np.mean(widths) + np.mean(heights)) * 100
            print(f"  í¬ê¸° ê· ì¼ì„±: {size_uniformity:.1f}%")

        print("="*60)

    def monitor_image(self, image_path: str, conf_threshold: float = 0.25, save_result: bool = True):
        """ì´ë¯¸ì§€ ëª¨ë‹ˆí„°ë§ ì „ì²´ í”„ë¡œì„¸ìŠ¤"""
        print(f"ğŸš— YOLO-OBB ëª¨ë‹ˆí„°ë§ ì‹œì‘: {image_path}")

        # 1. ê°ì§€ ì‹¤í–‰
        image, results = self.detect_with_obb(image_path, conf_threshold)
        if results is None:
            return None, None

        # 2. ê²°ê³¼ ì¶”ì¶œ
        detections = self.extract_detections(results)

        # 3. ìš”ì•½ ì¶œë ¥
        self.print_detection_summary(detections)

        # 4. ì§ì„  ê²€ì¶œ ë° Perspective Transform
        lines = self.detect_lines_from_obb(detections)
        transformed_image = None
        if image is not None:
            transformed_image = self.apply_perspective_transform(image, lines)

        # 5. ì‹œê°í™”
        save_path = None
        if save_result:
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            save_path = f"obb_monitor_result_{base_name}.png"

        fig = self.visualize_detections(image, detections, save_path, transformed_image, lines)

        return detections, fig


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” YOLO-OBB ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
    print("="*50)

    # ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    monitor = OBBMonitor()

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
    image_path = "../parkinglot1.jpg"

    if not os.path.exists(image_path):
        print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        print("ğŸ’¡ ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”:")
        possible_paths = [
            "../parkinglot1.jpg",
            "../../parkinglot1.jpg",
            "../data/parkinglot1.jpg",
            "parkinglot1.jpg"
        ]
        for path in possible_paths:
            if os.path.exists(path):
                print(f"âœ… ë°œê²¬: {path}")
                image_path = path
                break
            else:
                print(f"âŒ ì—†ìŒ: {path}")

        if not os.path.exists(image_path):
            return

    # ë‹¤ì–‘í•œ ì‹ ë¢°ë„ ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    confidence_levels = [0.1, 0.25, 0.5]

    for conf in confidence_levels:
        print(f"\nğŸ¯ ì‹ ë¢°ë„ ì„ê³„ê°’: {conf}")
        print("-" * 30)

        detections, fig = monitor.monitor_image(image_path, conf_threshold=conf, save_result=True)

        if detections:
            vehicles = [d for d in detections if d['is_vehicle']]
            if vehicles:
                print(f"âœ… {len(vehicles)}ëŒ€ ì°¨ëŸ‰ ê°ì§€ë¨")
            else:
                print("âš ï¸ ì°¨ëŸ‰ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        else:
            print("âŒ ê°ì§€ ê²°ê³¼ ì—†ìŒ")

        # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° (ë‹¤ìŒ í…ŒìŠ¤íŠ¸ë¡œ ë„˜ì–´ê°€ê¸°)
        if conf != confidence_levels[-1]:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´
            input("\nâ¸ï¸ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ë¡œ ë„˜ì–´ê°€ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤:")
    for file in os.listdir("."):
        if file.startswith("obb_monitor_result_"):
            print(f"   ğŸ’¾ {file}")


if __name__ == "__main__":
    main()